{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from microfilm import microplot\n",
    "\n",
    "from FUCCIDataset import FUCCIDatasetInMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = Path(\"/data/ishang/Fucci-dataset-v3_filtered/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset has some cache files and metadata in the home directory\n",
    "Then data separated by train, valid, test splits\n",
    "And then experiment folders inside. These folders contain the individual FOV images per channel.\n",
    "They also contain the sc cropped and downsampled images caches, and cell segmentation by products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of full FOV images: 2415\n",
      "/data/ishang/Fucci-dataset-v3_filtered/valid/Overview 1_Image 54--Stage13/cells_256.npy\n"
     ]
    }
   ],
   "source": [
    "# get all experiment image cache files\n",
    "image_cache_files = []\n",
    "for stage_split in dataset_dir.iterdir():\n",
    "    if not stage_split.is_dir():\n",
    "        continue\n",
    "    for experiment_dir in stage_split.iterdir():\n",
    "        if not experiment_dir.is_dir():\n",
    "            continue\n",
    "        for image_cache_file in experiment_dir.glob(\"cells_256.npy\"):\n",
    "            image_cache_files.append(dataset_dir / stage_split / experiment_dir / image_cache_file)\n",
    "\n",
    "print(\"Number of full FOV images:\", len(image_cache_files))\n",
    "print(image_cache_files[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below takes about 30 seconds to run, 10ish to load and 20 to concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all the images\n",
    "fucci_images = np.concatenate([np.load(image_cache_file) for image_cache_file in image_cache_files])\n",
    "print(fucci_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 55777, 256, 256])\n",
      "torch.float32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1.) tensor(1.)\n",
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "images = torch.from_numpy(fucci_images).permute(1, 0, 2, 3)\n",
    "print(images.shape)\n",
    "print(images.dtype)\n",
    "print(images.min(), images.max())\n",
    "print(torch.isfinite(images).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images are normalized -1 to 1 now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_names = [\"dapi\", \"tubulin\", \"geminin\", \"cdt1\"]\n",
    "for c, channel in enumerate(channel_names):\n",
    "    torch.save(images[c], dataset_dir / f\"{channel}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cdt1.pt\t\t\t     fucci_logvar.pt\t      reference_mu.pt\n",
      "colors.npy\t\t     fucci_mu.pt\t      reference_var.pt\n",
      "dapi.pt\t\t\t     geminin.pt\t\t      test\n",
      "fucci_embeddings_flipped.pt  index.csv\t\t      train\n",
      "fucci_embeddings.pt\t     reference_embeddings.pt  tubulin.pt\n",
      "fucci_indices\t\t     reference_indices\t      valid\n",
      "fucci_indices_flipped.npy    reference_indices.npy\n",
      "fucci_indices.npy\t     reference_logvar.pt\n"
     ]
    }
   ],
   "source": [
    "!ls $dataset_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takes 2.5 mins to run the below code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142790 35697 44621\n"
     ]
    }
   ],
   "source": [
    "from Dataset import MultiModalDataModule\n",
    "channel_names = [\"dapi\", \"tubulin\", \"geminin\", \"cdt1\"]\n",
    "dataset_dirs = [dataset_dir for _ in range(len(channel_names))]\n",
    "colors = [\"blue\", \"yellow\", \"green\", \"red\"]\n",
    "split = (0.64, 0.16, 0.2)\n",
    "batch_size = 8\n",
    "num_workers = 8\n",
    "dm = MultiModalDataModule(dataset_dirs, channel_names, colors, \"combined\", split, batch_size, num_workers)\n",
    "print(len(dm.data_train), len(dm.data_val), len(dm.data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 256])\n",
      "torch.Size([256, 256])\n"
     ]
    }
   ],
   "source": [
    "print(dm.data_train[0].shape)\n",
    "print(next(iter(dm.train_dataloader()))[0].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "implicit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
