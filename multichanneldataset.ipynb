{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from microfilm import microplot\n",
    "\n",
    "from FUCCIDataset import FUCCIDatasetInMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = Path(\"/data/ishang/Fucci-dataset-v3_filtered/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset has some cache files and metadata in the home directory\n",
    "Then data separated by train, valid, test splits\n",
    "And then experiment folders inside. These folders contain the individual FOV images per channel.\n",
    "They also contain the sc cropped and downsampled images caches, and cell segmentation by products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of full FOV images: 2415\n",
      "/data/ishang/Fucci-dataset-v3_filtered/valid/Overview 1_Image 54--Stage13/cells_256.npy\n"
     ]
    }
   ],
   "source": [
    "# get all experiment image cache files\n",
    "image_cache_files = []\n",
    "for stage_split in dataset_dir.iterdir():\n",
    "    if not stage_split.is_dir():\n",
    "        continue\n",
    "    for experiment_dir in stage_split.iterdir():\n",
    "        if not experiment_dir.is_dir():\n",
    "            continue\n",
    "        for image_cache_file in experiment_dir.glob(\"cells_256.npy\"):\n",
    "            image_cache_files.append(dataset_dir / stage_split / experiment_dir / image_cache_file)\n",
    "\n",
    "print(\"Number of full FOV images:\", len(image_cache_files))\n",
    "print(image_cache_files[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below takes about 30 seconds to run, 10ish to load and 20 to concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all the images\n",
    "fucci_images = np.concatenate([np.load(image_cache_file) for image_cache_file in image_cache_files])\n",
    "print(fucci_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 55777, 256, 256])\n",
      "torch.float32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1.) tensor(1.)\n",
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "images = torch.from_numpy(fucci_images).permute(1, 0, 2, 3)\n",
    "print(images.shape)\n",
    "print(images.dtype)\n",
    "print(images.min(), images.max())\n",
    "print(torch.isfinite(images).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images are normalized -1 to 1 now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_names = [\"dapi\", \"tubulin\", \"geminin\", \"cdt1\"]\n",
    "for c, channel in enumerate(channel_names):\n",
    "    torch.save(images[c], dataset_dir / f\"{channel}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cdt1.pt\t\t\t     fucci_logvar.pt\t      reference_mu.pt\n",
      "colors.npy\t\t     fucci_mu.pt\t      reference_var.pt\n",
      "dapi.pt\t\t\t     geminin.pt\t\t      test\n",
      "fucci_embeddings_flipped.pt  index.csv\t\t      train\n",
      "fucci_embeddings.pt\t     reference_embeddings.pt  tubulin.pt\n",
      "fucci_indices\t\t     reference_indices\t      valid\n",
      "fucci_indices_flipped.npy    reference_indices.npy\n",
      "fucci_indices.npy\t     reference_logvar.pt\n"
     ]
    }
   ],
   "source": [
    "!ls $dataset_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takes 2.5 mins to run the below code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Dataset import MultiModalDataModule\n",
    "channel_names = [\"dapi\", \"tubulin\", \"geminin\", \"cdt1\"]\n",
    "dataset_dirs = [dataset_dir for _ in range(len(channel_names))]\n",
    "colors = [\"blue\", \"yellow\", \"green\", \"red\"]\n",
    "split = (0.64, 0.16, 0.2)\n",
    "batch_size = 8\n",
    "num_workers = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142790 35697 44621\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dm = MultiModalDataModule(dataset_dirs, channel_names, colors, \"combined\", split, batch_size, num_workers)\n",
    "print(len(dm.data_train), len(dm.data_val), len(dm.data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "print(dm.data_train[0].shape)\n",
    "print(next(iter(dm.train_dataloader()))[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dapi\n",
      "dapi loaded, shape: torch.Size([55777, 256, 256])\n",
      "saving shards\n",
      "Saving dapi_0.pt\n",
      "Saving dapi_1.pt\n",
      "Saving dapi_2.pt\n",
      "Saving dapi_3.pt\n",
      "Saving dapi_4.pt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, data\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], shard_size):\n\u001b[1;32m      8\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSaving \u001b[39m\u001b[39m{\u001b[39;00mdataset\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mint\u001b[39m(i\u001b[39m \u001b[39m\u001b[39m/\u001b[39m\u001b[39m \u001b[39mshard_size)\u001b[39m}\u001b[39;00m\u001b[39m.pt\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m     torch\u001b[39m.\u001b[39;49msave(data[i:i\u001b[39m+\u001b[39;49mshard_size], dataset_dir \u001b[39m/\u001b[39;49m \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mdataset\u001b[39m}\u001b[39;49;00m\u001b[39m_\u001b[39;49m\u001b[39m{\u001b[39;49;00m\u001b[39mint\u001b[39;49m(i\u001b[39m \u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39m \u001b[39;49mshard_size)\u001b[39m}\u001b[39;49;00m\u001b[39m.pt\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/implicit/lib/python3.10/site-packages/torch/serialization.py:441\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[39mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[1;32m    440\u001b[0m     \u001b[39mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[39mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m--> 441\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol)\n\u001b[1;32m    442\u001b[0m         \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    443\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/implicit/lib/python3.10/site-packages/torch/serialization.py:668\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[39m# Now that it is on the CPU we can directly copy it into the zip file\u001b[39;00m\n\u001b[1;32m    667\u001b[0m num_bytes \u001b[39m=\u001b[39m storage\u001b[39m.\u001b[39mnbytes()\n\u001b[0;32m--> 668\u001b[0m zip_file\u001b[39m.\u001b[39;49mwrite_record(name, storage\u001b[39m.\u001b[39;49mdata_ptr(), num_bytes)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "shard_size = 1000\n",
    "for dataset in channel_names:\n",
    "    print(f\"loading {dataset}\")\n",
    "    data = torch.load(dataset_dir / f\"{dataset}.pt\")\n",
    "    print(f\"{dataset} loaded, shape: {data.shape}\")\n",
    "    print(\"saving shards\")\n",
    "    for i in range(0, data.shape[0], shard_size):\n",
    "        print(f\"Saving {dataset}_{int(i / shard_size)}.pt\")\n",
    "        torch.save(data[i:i+shard_size], dataset_dir / f\"{dataset}_{int(i / shard_size)}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dapi\n",
      "dapi loaded, shape: torch.Size([55777, 256, 256])\n",
      "saving shards\n",
      "[0, 1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000, 11000, 12000, 13000, 14000, 15000, 16000, 17000, 18000, 19000, 20000, 21000, 22000, 23000, 24000, 25000, 26000, 27000, 28000, 29000, 30000, 31000, 32000, 33000, 34000, 35000, 36000, 37000, 38000, 39000, 40000, 41000, 42000, 43000, 44000, 45000, 46000, 47000, 48000, 49000, 50000, 51000, 52000, 53000, 54000, 55000]\n",
      "Saving dapi_0.ptSaving dapi_2.ptSaving dapi_10.ptSaving dapi_12.ptSaving dapi_14.ptSaving dapi_6.ptSaving dapi_8.ptSaving dapi_4.pt\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Saving dapi_3.pt\n",
      "Saving dapi_11.pt\n",
      "Saving dapi_7.pt\n",
      "Saving dapi_15.pt\n",
      "Saving dapi_5.pt\n",
      "Saving dapi_9.pt\n",
      "Saving dapi_13.pt\n",
      "Saving dapi_1.pt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlist\u001b[39m(\u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(data), shard_size)))\n\u001b[1;32m     17\u001b[0m \u001b[39mwith\u001b[39;00m Pool(\u001b[39m8\u001b[39m) \u001b[39mas\u001b[39;00m p:\n\u001b[0;32m---> 18\u001b[0m     p\u001b[39m.\u001b[39;49mmap(save_shard, \u001b[39mlist\u001b[39;49m(\u001b[39mrange\u001b[39;49m(\u001b[39m0\u001b[39;49m, \u001b[39mlen\u001b[39;49m(data), shard_size)))\n",
      "File \u001b[0;32m~/miniconda3/envs/implicit/lib/python3.10/multiprocessing/pool.py:367\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmap\u001b[39m(\u001b[39mself\u001b[39m, func, iterable, chunksize\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    363\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[39m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[39m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[0;32m--> 367\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_map_async(func, iterable, mapstar, chunksize)\u001b[39m.\u001b[39;49mget()\n",
      "File \u001b[0;32m~/miniconda3/envs/implicit/lib/python3.10/multiprocessing/pool.py:768\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 768\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    769\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mready():\n\u001b[1;32m    770\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/implicit/lib/python3.10/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwait\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_event\u001b[39m.\u001b[39;49mwait(timeout)\n",
      "File \u001b[0;32m~/miniconda3/envs/implicit/lib/python3.10/threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flag\n\u001b[1;32m    606\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 607\u001b[0m     signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cond\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    608\u001b[0m \u001b[39mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/miniconda3/envs/implicit/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "import sys\n",
    "\n",
    "shard_size = 1000\n",
    "for dataset in channel_names:\n",
    "    print(f\"loading {dataset}\")\n",
    "    data = torch.load(dataset_dir / f\"{dataset}.pt\")\n",
    "    print(f\"{dataset} loaded, shape: {data.shape}\")\n",
    "    print(\"saving shards\")\n",
    "\n",
    "    def save_shard(i):\n",
    "        print(f\"Saving {dataset}_{int(i / shard_size)}.pt\")\n",
    "        sys.stdout.flush()\n",
    "        torch.save(data[i:min(i+shard_size, len(data))], dataset_dir / f\"{dataset}_{int(i / shard_size)}.pt\")\n",
    "    \n",
    "    print(list(range(0, len(data), shard_size)))\n",
    "    with Pool(8) as p:\n",
    "        p.map(save_shard, list(range(0, len(data), shard_size)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "implicit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
