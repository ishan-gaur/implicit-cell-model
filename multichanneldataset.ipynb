{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from microfilm import microplot\n",
    "\n",
    "from FUCCIDataset import FUCCIDatasetInMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = Path(\"/data/ishang/Fucci-dataset-v3_filtered/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset has some cache files and metadata in the home directory\n",
    "Then data separated by train, valid, test splits\n",
    "And then experiment folders inside. These folders contain the individual FOV images per channel.\n",
    "They also contain the sc cropped and downsampled images caches, and cell segmentation by products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_index = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of full FOV images: 2415\n",
      "/data/ishang/Fucci-dataset-v3_filtered/valid/Overview 1_Image 54--Stage13/cells_256.npy\n"
     ]
    }
   ],
   "source": [
    "# get all experiment image cache files\n",
    "image_cache_files = []\n",
    "for stage_split in dataset_dir.iterdir():\n",
    "    if not stage_split.is_dir():\n",
    "        continue\n",
    "    for experiment_dir in stage_split.iterdir():\n",
    "        if not experiment_dir.is_dir():\n",
    "            continue\n",
    "        for image_cache_file in experiment_dir.glob(\"cells_256.npy\"):\n",
    "            image_cache_files.append(dataset_dir / stage_split / experiment_dir / image_cache_file)\n",
    "\n",
    "print(\"Number of full FOV images:\", len(image_cache_files))\n",
    "print(image_cache_files[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below takes about 30 seconds to run, 10ish to load and 20 to concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all the images\n",
    "fucci_images = np.concatenate([np.load(image_cache_file) for image_cache_file in image_cache_files])\n",
    "print(fucci_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 55777, 256, 256])\n",
      "torch.float32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1.) tensor(1.)\n",
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "images = torch.from_numpy(fucci_images).permute(1, 0, 2, 3)\n",
    "print(images.shape)\n",
    "print(images.dtype)\n",
    "print(images.min(), images.max())\n",
    "print(torch.isfinite(images).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images are normalized -1 to 1 now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_names = [\"dapi\", \"tubulin\", \"geminin\", \"cdt1\"]\n",
    "for c, channel in enumerate(channel_names):\n",
    "    torch.save(images[c], dataset_dir / f\"{channel}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cdt1.pt\t\t\t     fucci_logvar.pt\t      reference_mu.pt\n",
      "colors.npy\t\t     fucci_mu.pt\t      reference_var.pt\n",
      "dapi.pt\t\t\t     geminin.pt\t\t      test\n",
      "fucci_embeddings_flipped.pt  index.csv\t\t      train\n",
      "fucci_embeddings.pt\t     reference_embeddings.pt  tubulin.pt\n",
      "fucci_indices\t\t     reference_indices\t      valid\n",
      "fucci_indices_flipped.npy    reference_indices.npy\n",
      "fucci_indices.npy\t     reference_logvar.pt\n"
     ]
    }
   ],
   "source": [
    "!ls $dataset_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class ImageChannelDataset(Dataset):\n",
    "    def __init__(self, dataset_dir, channel_name, color=None):\n",
    "        self.dataset_dir = dataset_dir\n",
    "        self.channel_name = channel_name\n",
    "        self.images = torch.load(self.dataset_dir / f\"{self.channel_name}.pt\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images) \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.images[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55777\n"
     ]
    }
   ],
   "source": [
    "dapi_dataset = ImageChannelDataset(dataset_dir, \"dapi\", \"blue\")\n",
    "print(len(dapi_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SimpleDataset(Dataset):\n",
    "    def __init__(self, tensor) -> None:\n",
    "        self.tensor = tensor\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.tensor[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.tensor.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning import LightningDataModule\n",
    "from lightning.pytorch.utilities.types import EVAL_DATALOADERS\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "class MultiModalDataModule(LightningDataModule):\n",
    "    def __init__(self, datasets, mode, split, batch_size, num_workers):\n",
    "        super().__init__()\n",
    "        self.datasets = [dataset[:] for dataset in datasets]\n",
    "        self.split = split\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.mode = mode\n",
    "    \n",
    "        if self.mode not in self.modes():\n",
    "            raise ValueError(f\"Mode must be one of {self.modes()}. Got {mode}.\")\n",
    "        if self.mode == \"paired\":\n",
    "            # stack should give us (modalities, samples, ...)\n",
    "            # then swapaxes should give us (samples, modalities, ...) so that they are paired\n",
    "            self.dataset = torch.stack(self.datasets).swapaxes(0, 1)\n",
    "        elif self.mode == \"unpaired\":\n",
    "            # stack should give us (modalities, samples, ...)\n",
    "            self.dataset = torch.stack(self.datasets)\n",
    "            raise NotImplementedError(\"Unpaired mode not implemented yet.\")\n",
    "        elif self.mode == \"combined\":\n",
    "            self.dataset = torch.cat(self.datasets)\n",
    "\n",
    "        self.dataset = SimpleDataset(self.dataset)\n",
    "\n",
    "        if len(self.split) != 3:\n",
    "            raise ValueError(\"split must be a tuple of length 3\")\n",
    "        self.data_train, self.data_val, self.data_test = random_split(self.dataset, self.split)\n",
    "\n",
    "    def modes(self):\n",
    "        return [\"paired\", \"unpaired\", \"combined\"]\n",
    "\n",
    "    def __shared_dataloader(self, dataset, shuffle=True):\n",
    "        return DataLoader(dataset, batch_size=self.batch_size, num_workers=self.num_workers, persistent_workers=True)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return self.__shared_dataloader(self.data_train)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return self.__shared_dataloader(self.data_val, shuffle=False)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return self.__shared_dataloader(self.data_test, shuffle=False)\n",
    "\n",
    "    def predict_dataloader(self):\n",
    "        return super().predict_dataloader()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below takes about 1.5 mins to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [ImageChannelDataset(dataset_dir, c) for c in channel_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142790 35697 44621\n"
     ]
    }
   ],
   "source": [
    "from Dataset import MultiModalDataModule as mmdm\n",
    "dm = mmdm(datasets, \"combined\", (0.64, 0.16, 0.2), 8, 1)\n",
    "print(len(dm.data_train), len(dm.data_val), len(dm.data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(dm\u001b[39m.\u001b[39mdata_train[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mshape)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dm' is not defined"
     ]
    }
   ],
   "source": [
    "print(dm.data_train[0].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "implicit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
