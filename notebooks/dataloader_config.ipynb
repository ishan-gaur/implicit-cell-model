{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FUCCIDataset import ReferenceChannelDataset\n",
    "FUCCI_PATH = '/data/ishang/Fucci-dataset-v3_filtered'\n",
    "res = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ReferenceChannelDataset(FUCCI_PATH, imsize=res)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takes 36 seconds to load the dataset for a given process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 55777\n",
      "train: 35697, val: 8924, test: 11155\n"
     ]
    }
   ],
   "source": [
    "print(f\"total: {len(dataset)}\")\n",
    "print(f\"train: {int(len(dataset) * 0.8 * 0.8)}, val: {int(len(dataset) * 0.8 * 0.2)}, test: {int(len(dataset) * 0.2)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "36k images, 32bit floats, 256*256*2 numbers: 19 gigabytes total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.874368"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "36e3*4*256*256*2/1e9"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "at batch size 32, 16 workers, rose-bird-52 used about 4.5GB at steady state. Looks like the readout in the chart is gigabits?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.536870912"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "16 * 2 * 32 * 256 * 256 * 2 * 4 / 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.294967296"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "16 * 2 * 32 * 256 * 256 * 2 * 4 / 1e9 * 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\n",
      "Mem:        1031875       24179      945916         222       61779     1002191\n",
      "Swap:             0           0           0\n"
     ]
    }
   ],
   "source": [
    "!free -m"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there is like 1T of memory"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So for the datasize we have the following number of batches and how many will be covered by the number workers? Does it exeed the system memory?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches: 1488\n",
      "Workers can concurrently load 512 batches\n",
      "Which means 3 loading periods will be needed\n",
      "At one time, they will need 51.539607552 GiB of memory\n"
     ]
    }
   ],
   "source": [
    "batch_size = 24\n",
    "num_workers = 256\n",
    "prefetch_factor = 2\n",
    "\n",
    "batch_n = int(len(dataset) * 0.8 * 0.8 / batch_size) + 1\n",
    "print(f\"Number of batches: {batch_n}\")\n",
    "print(f\"Workers can concurrently load {num_workers * prefetch_factor} batches\")\n",
    "print(f\"Which means {int(batch_n / (num_workers * prefetch_factor)) + 1} loading periods will be needed\")\n",
    "print(f\"At one time, they will need {num_workers * prefetch_factor * batch_size * res * res * 2 * 32 / 1e9} GiB of memory\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Honestly this will probably be limited by the process memory and disk bandwidth to begin with. 256 is too much.\n",
    "With a bigger batchsize, the model computation time will be longer so you can have less workers. But the upfront time might be too big. Could be better to do tiny batches and a shit ton of workers..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "implicit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
