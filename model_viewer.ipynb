{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LightningModules import AutoEncoder, FUCCIDataModule, ReconstructionVisualization\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from microfilm import microplot\n",
    "import torch\n",
    "from kornia import tensor_to_image\n",
    "from microfilm.colorify import multichannel_to_rgb\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "FUCCI_PATH = '/home/ishang/cross-modal-autoencoders/FUCCI-dev-data'\n",
    "res = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# project_name = f\"FUCCI_{args.model}_VAE\"\n",
    "# wandb_logger = WandbLogger(\n",
    "#     project=project_name,\n",
    "#     log_model=True,\n",
    "#     save_dir=\"/data/ishang/fucci_vae/wandb_logs\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = FUCCIDataModule(\n",
    "    data_dir=FUCCI_PATH,\n",
    "    dataset=\"reference\",\n",
    "    imsize=res,\n",
    "    split=(0.8, 0.1, 0.1),\n",
    "    batch_size=8,\n",
    "    num_workers=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_with_time(\"Setting up Autoencoder...\")\n",
    "# encoder = Encoder(nc=2 if args.model in [\"reference\", \"fucci\"] else 4, imsize=config.imsize)\n",
    "# decoder = Decoder(nc=2 if args.model in [\"reference\", \"fucci\"] else 4, imsize=config.imsize)\n",
    "# model = AutoEncoder(encoder, decoder, lr=config.lr)\n",
    "\n",
    "\n",
    "# trainer = pl.Trainer(\n",
    "#     default_root_dir=f\"/data/ishang/fucci_vae/lightning_logs/{project_name}\",\n",
    "#     accelerator=\"gpu\",\n",
    "#     devices=8,\n",
    "#     # accelerator=\"cpu\",\n",
    "#     # fast_dev_run=10,\n",
    "#     # detect_anomaly=True,\n",
    "#     num_sanity_val_steps=2,\n",
    "#     # overfit_batches=5,\n",
    "#     # log_every_n_steps=10,\n",
    "#     logger=wandb_logger,\n",
    "#     max_epochs=100,\n",
    "#     callbacks=[\n",
    "#         EarlyStopping(monitor=\"val/loss\", min_delta=config.min_delta, mode=\"min\"),\n",
    "#         LearningRateMonitor(logging_interval='step')\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2, 512, 512])\n",
      "torch.Size([2, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "print(dm.dataset[:3].shape)\n",
    "print(dm.dataset[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = ReconstructionVisualization.make_reconstruction_grid(dm.train_dataloader().dataset[:3], dm.val_dataloader().dataset[:3])\n",
    "print(grid.shape)\n",
    "cmap = ['pure_blue', 'pure_yellow', 'pure_green', 'pure_red']\n",
    "img = np.moveaxis(tensor_to_image(grid), -1, 0)\n",
    "print(img.shape)\n",
    "microplot.microshow(images=img, cmaps=cmap[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 776, 518)\n",
      "<class 'numpy.ndarray'>\n",
      "(776, 518, 4)\n",
      "float64\n",
      "[0. 0. 0. 1.]\n",
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(img.shape)\n",
    "image_composite, _, _, _= multichannel_to_rgb(img, cmaps=cmap[:2])\n",
    "print(type(image_composite))\n",
    "print(image_composite.shape)\n",
    "print(image_composite.dtype)\n",
    "print(image_composite[350, 250])\n",
    "print(np.max(image_composite[:, :, 0]))\n",
    "print(np.min(image_composite[:, :, 0]))\n",
    "image_composite = (255 * image_composite).astype(np.uint8)\n",
    "image_composite = Image.fromarray(image_composite)\n",
    "image_composite.save(f'test_grid_{res}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 776, 518])\n",
      "(2, 776, 518)\n"
     ]
    }
   ],
   "source": [
    "from kornia import tensor_to_image\n",
    "from microfilm.colorify import multichannel_to_rgb\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "grid = ReconstructionVisualization.make_reconstruction_grid(dm.dataset[:3], dm.dataset[:3])\n",
    "print(grid.shape)\n",
    "img = np.moveaxis(tensor_to_image(grid), -1, 0)\n",
    "print(img.shape)\n",
    "image_composite, _, _, _= multichannel_to_rgb(img, cmaps=dm.dataset.channel_colors())\n",
    "image_composite = (255 * image_composite).astype(np.uint8)\n",
    "image_composite = Image.fromarray(image_composite)\n",
    "image_composite.save(f'test_grid_{res}_composite.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "implicit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
